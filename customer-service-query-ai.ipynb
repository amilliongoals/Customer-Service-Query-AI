{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The goal of this is to create a ai query chatbot for a customer service rep to use during phone calls to align with company policy. \n\nRather than searching and reading through policy mid-call this can take prompt systems and documentation to create an highly effective response system to improve customer satisfaction. \n","metadata":{}},{"cell_type":"code","source":"#pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2023-12-05T21:02:31.383571Z","iopub.execute_input":"2023-12-05T21:02:31.383993Z","iopub.status.idle":"2023-12-05T21:02:31.388535Z","shell.execute_reply.started":"2023-12-05T21:02:31.383960Z","shell.execute_reply":"2023-12-05T21:02:31.387524Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"https://pypi.org/project/tiktoken/ \n\nAbout TikToken:\n\n\ntiktoken contains an educational submodule that is friendlier if you want to learn more about the details of BPE, including code that helps visualise the BPE procedure:\n\nModels don't see text like you and I, instead they see a sequence of numbers (known as tokens). Byte pair encoding (BPE) is a way of converting text into tokens. It has a couple desirable properties:\n\nIt's reversible and lossless, so you can convert tokens back into the original text\nIt works on arbitrary text, even text that is not in the tokeniser's training data\nIt compresses the text: the token sequence is shorter than the bytes corresponding to the original text. On average, in practice, each token corresponds to about 4 bytes.\nIt attempts to let the model see common subwords. For instance, \"ing\" is a common subword in English, so BPE encodings will often split \"encoding\" into tokens like \"encod\" and \"ing\" (instead of e.g. \"enc\" and \"oding\"). Because the model will then see the \"ing\" token again and again in different contexts, it helps models generalise and better understand grammar.","metadata":{}},{"cell_type":"code","source":"#pip install openai\n#!pip install scikit-learn","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:16:33.033405Z","iopub.execute_input":"2023-12-05T20:16:33.033836Z","iopub.status.idle":"2023-12-05T20:16:33.037654Z","shell.execute_reply.started":"2023-12-05T20:16:33.033799Z","shell.execute_reply":"2023-12-05T20:16:33.037004Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"https://pypi.org/project/openai/\n\nThe Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling. In the future, we plan to release more OpenAI-built tools, and allow you to provide your own tools on our platform.\n\nYou can explore the capabilities of the Assistants API using the Assistants playground or by building a step-by-step integration outlined in this guide. At a high level, a typical integration of the Assistants API has the following flow:\n","metadata":{}},{"cell_type":"code","source":"import os\nimport tiktoken #open-source tokenizer by OpenAI.\nimport pandas as pd\nfrom openai import OpenAI\nimport numpy as np\nfrom ast import literal_eval\nfrom openai import OpenAI\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"OPENAI_API_KEY\")\n\nos.environ['OPENAI_API_KEY'] = secret_value_0\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-05T21:02:25.479891Z","iopub.execute_input":"2023-12-05T21:02:25.480359Z","iopub.status.idle":"2023-12-05T21:02:25.796330Z","shell.execute_reply.started":"2023-12-05T21:02:25.480325Z","shell.execute_reply":"2023-12-05T21:02:25.795301Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"https://platform.openai.com/docs/quickstart?context=python","metadata":{}}]}